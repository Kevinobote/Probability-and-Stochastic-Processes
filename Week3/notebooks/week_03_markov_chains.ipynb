{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weeks 3-4: Markov Chains\n",
    "\n",
    "**Objective:** Understand the Markov property, represent a system using a transition probability matrix, simulate its behavior, and calculate its long-run (stationary) distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Build Intuition\n",
    "\n",
    "Imagine you want to predict tomorrow's weather. You could look at the weather for the past month, but a simpler, often effective, strategy is to just look at today's weather. If it's sunny today, there's a certain chance it will be sunny tomorrow, and a certain chance it will be rainy. The key idea is that **the future depends only on the present, not the past**.\n",
    "\n",
    "This \"memoryless\" property is the heart of a Markov Chain. It doesn't matter if it was rainy for the last 10 days; if today is sunny, the prediction for tomorrow is based *only* on the fact that today is sunny.\n",
    "\n",
    "**Examples:**\n",
    "- A board game where your next position depends only on your current square and a dice roll.\n",
    "- A customer's brand loyalty: their next purchase depends on the brand they bought last, not their entire purchase history.\n",
    "- The random walk from last week is a perfect example of a Markov Chain!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Understand the Core Idea\n",
    "\n",
    "To define a Markov Chain, we need three things:\n",
    "\n",
    "1.  **State Space:** A set of all possible conditions or states the system can be in. For our weather example, the state space is `S = {Sunny, Rainy}`.\n",
    "2.  **Transition Probabilities:** The probabilities of moving from one state to another in a single time step. For example, the probability of moving from `Sunny` to `Rainy`.\n",
    "3.  **Markov Property:** The probability of moving to the next state `j` depends *only* on the current state `i`. It is independent of all past states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Learn the Definitions and Formulas\n",
    "\n",
    "**Definition: Markov Chain**\n",
    "A discrete-time stochastic process \\({X_n, n \\ge 0}\\) is a Markov chain if it satisfies the Markov property:\n",
    "$$ P(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, ..., X_0 = i_0) = P(X_{n+1} = j | X_n = i) $$\n",
    "for all time steps \\(n\\) and all states \\(i, j, i_0, ...\\).\n",
    "\n",
    "--- \n",
    "\n",
    "**Definition: Transition Probability Matrix (TPM)**\n",
    "We can organize the transition probabilities into a matrix \\(P\\), where the entry \\(P_{ij}\\) is the probability of moving from state \\(i\\) to state \\(j\\) in one step.\n",
    "$$ P_{ij} = P(X_{n+1} = j | X_n = i) $$\n",
    "\n",
    "For our weather example, let's define the states as `0 = Sunny` and `1 = Rainy`. The TPM could be:\n",
    "\n",
    "$$ P = \\begin{pmatrix} P(S \\to S) & P(S \\to R) \\\\ P(R \\to S) & P(R \\to R) \\end{pmatrix} = \\begin{pmatrix} 0.9 & 0.1 \\\\ 0.5 & 0.5 \\end{pmatrix} $$\n",
    "\n",
    "**Properties of a TPM:**\n",
    "1. All entries must be non-negative: \\(P_{ij} \\ge 0\\).\n",
    "2. The sum of each row must be 1 (from any state, you must transition to *some* other state): \\(\\sum_j P_{ij} = 1\\) for all \\(i\\).\n",
    "\n",
    "--- \n",
    "\n",
    "**Definition: Stationary Distribution (or Equilibrium)**\n",
    "A stationary distribution is a probability distribution \\(\\pi\\) over the states that does not change over time. If the system reaches this distribution, it will stay there. It is a row vector \\(\\pi\\) that satisfies:\n",
    "$$ \\pi P = \\pi $$\n",
    "This means \\(\\pi\\) is a **left eigenvector** of the matrix \\(P\\) with an eigenvalue of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Apply and Practice\n",
    "\n",
    "Let's use Python to model the weather example. We'll define the TPM, simulate the weather over a month, and then calculate the stationary distribution to find the long-term weather forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Defining the System and Simulating\n",
    "\n",
    "First, let's define our states and the Transition Probability Matrix (TPM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State space: 0 for Sunny, 1 for Rainy\n",
    "states = ['Sunny', 'Rainy']\n",
    "\n",
    "# Transition Probability Matrix (TPM)\n",
    "# P[i, j] is the probability of transitioning from state i to state j\n",
    "P = np.array([\n",
    "    [0.9, 0.1],  # P(Sunny -> Sunny), P(Sunny -> Rainy)\n",
    "    [0.5, 0.5]   # P(Rainy -> Sunny), P(Rainy -> Rainy)\n",
    "])\n",
    "\n",
    "print(\"Transition Matrix P:\\n\", P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's simulate the weather for 30 days, assuming it starts as Sunny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_weather(tpm, num_days, start_state=0):\n",
    "    \"\"\"Simulates a path of the Markov chain.\"\"\"\n",
    "    num_states = tpm.shape[0]\n",
    "    path = [start_state]\n",
    "    current_state = start_state\n",
    "    \n",
    "    for _ in range(num_days - 1):\n",
    "        # Get the transition probabilities for the current state\n",
    "        transition_probs = tpm[current_state, :]\n",
    "        # Choose the next state based on these probabilities\n",
    "        next_state = np.random.choice(np.arange(num_states), p=transition_probs)\n",
    "        path.append(next_state)\n",
    "        current_state = next_state\n",
    "        \n",
    "    return path\n",
    "\n",
    "# Simulate for 30 days, starting with a Sunny day (state 0)\n",
    "N_DAYS = 30\n",
    "weather_path = simulate_weather(P, N_DAYS, start_state=0)\n",
    "\n",
    "# Convert numeric path to state names for readability\n",
    "weather_forecast = [states[i] for i in weather_path]\n",
    "\n",
    "print(f\"Simulated weather for {N_DAYS} days:\")\n",
    "print(\" -> \".join(weather_forecast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Multi-Step Transitions\n",
    "\n",
    "What is the probability of the weather being Rainy 3 days from now, if it is Sunny today? This is given by the (0, 1) entry of the matrix \\(P^3\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the probabilities after n steps, we compute P^n\n",
    "# Let's find the 3-day transition matrix\n",
    "P_3_days = np.linalg.matrix_power(P, 3)\n",
    "\n",
    "print(\"Transition Matrix after 3 days (P^3):\\n\", P_3_days)\n",
    "\n",
    "prob_sunny_to_rainy_3_days = P_3_days[0, 1]\n",
    "print(f\"\\nProbability of it being Rainy in 3 days, given it's Sunny today: {prob_sunny_to_rainy_3_days:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Stationary Distribution\n",
    "\n",
    "What is the long-term probability of a day being Sunny or Rainy? We need to find the stationary distribution \\(\\pi\\) such that \\(\\pi P = \\pi\\).\n",
    "\n",
    "This is equivalent to finding the left eigenvector of \\(P\\) corresponding to the eigenvalue 1. We can rewrite \\(\\pi P = \\pi\\) as \\(\\pi (P - I) = 0\\), where \\(I\\) is the identity matrix. In NumPy, we find the *right* eigenvectors, so we work with the transpose: \\((P^T - I^T) \\pi^T = 0\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stationary_distribution(tpm):\n",
    "    \"\"\"Calculates the stationary distribution of a Markov chain.\"\"\"\n",
    "    # We need to solve pi * P = pi, which is equivalent to pi * (P - I) = 0\n",
    "    # This means pi is the left eigenvector of P with eigenvalue 1.\n",
    "    # In numpy, we find right eigenvectors, so we work with P.T\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(tpm.T)\n",
    "    \n",
    "    # Find the eigenvector corresponding to the eigenvalue 1\n",
    "    # Note: due to floating point, we check for closeness to 1\n",
    "    stationary_vector = eigenvectors[:, np.isclose(eigenvalues, 1)]\n",
    "    \n",
    "    # The eigenvector is complex by default, so take the real part\n",
    "    # and normalize it to sum to 1\n",
    "    stationary_dist = stationary_vector.real\n",
    "    stationary_dist /= stationary_dist.sum()\n",
    "    \n",
    "    return stationary_dist.flatten()\n",
    "\n",
    "pi = find_stationary_distribution(P)\n",
    "\n",
    "print(f\"The stationary distribution is:\")\n",
    "print(f\"- Probability of Sunny: {pi[0]:.4f}\")\n",
    "print(f\"- Probability of Rainy: {pi[1]:.4f}\")\n",
    "\n",
    "# Verification: Check if pi * P = pi\n",
    "print(\"\\nVerification (pi * P):\", pi @ P)\n",
    "print(\"Original pi:\", pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result means that in the long run, about 83.3% of days will be sunny, and 16.7% will be rainy, regardless of the weather on day 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Convergence to Stationary Distribution\n",
    "\n",
    "Let's see how the probability distribution evolves over time. We'll start with a 100% chance of being Sunny (`[1, 0]`) and see how many steps it takes to get close to `pi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a sunny day: initial distribution is [1, 0]\n",
    "initial_dist = np.array([1, 0])\n",
    "\n",
    "n_steps = 15\n",
    "prob_history = np.zeros((n_steps, 2))\n",
    "prob_history[0, :] = initial_dist\n",
    "\n",
    "current_dist = initial_dist\n",
    "for i in range(1, n_steps):\n",
    "    current_dist = current_dist @ P\n",
    "    prob_history[i, :] = current_dist\n",
    "\n",
    "# Plot the convergence\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(prob_history[:, 0], label='P(State = Sunny)', marker='o')\n",
    "plt.plot(prob_history[:, 1], label='P(State = Rainy)', marker='o')\n",
    "\n",
    "# Plot the stationary distribution as horizontal lines\n",
    "plt.axhline(y=pi[0], color='blue', linestyle='--', label=f'Stationary Sunny ({pi[0]:.2f})')\n",
    "plt.axhline(y=pi[1], color='orange', linestyle='--', label=f'Stationary Rainy ({pi[1]:.2f})')\n",
    "\n",
    "plt.title('Convergence to Stationary Distribution')\n",
    "plt.xlabel('Number of Days (Steps)')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the plot, the probabilities converge very quickly to their long-run equilibrium values, usually within 5-10 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "In this notebook, we've covered the fundamentals of discrete-time Markov Chains:\n",
    "1.  The **Markov Property**: The future depends only on the present.\n",
    "2.  The **Transition Probability Matrix (TPM)** as the engine of the chain.\n",
    "3.  How to **simulate** a path of a Markov Chain.\n",
    "4.  How to calculate **multi-step transition probabilities** using matrix powers.\n",
    "5.  The concept of a **stationary distribution** and how to calculate it by finding the eigenvector of the TPM.\n",
    "\n",
    "Next, we will explore **Hidden Markov Models (HMMs)**. What if we can't observe the state directly (e.g., we don't know if it's Sunny or Rainy), but can only see a related output (e.g., we see people carrying umbrellas)? HMMs allow us to model such systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}