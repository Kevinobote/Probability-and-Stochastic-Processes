{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weeks 12-13: Advanced Queuing Models (The M/M/s Queue)\n",
    "\n",
    "**Objective:** Extend the M/M/1 model to the multi-server case (M/M/s), learn the formulas for its performance metrics, and compare the performance of single-server vs. multi-server systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Build Intuition\n",
    "\n",
    "In the last notebook, we analyzed a coffee shop with one barista. We saw that as the customer arrival rate got close to the barista's service rate (i.e., as utilization \\(\\rho\\) approached 1), the waiting times grew exponentially. \n",
    "\n",
    "The obvious solution to long queues is to add more capacity. What happens if the coffee shop owner hires a second barista? We now have two parallel servers. Customers still arrive in a single line, but the person at the front of the line goes to the next available barista.\n",
    "\n",
    "This is an **M/M/s queue** (in our case, M/M/2). Intuitively, we expect this system to be much more efficient. The wait times should be shorter, and the line should be smaller. Queuing theory allows us to precisely quantify *how much* better the system gets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Understand the Core Idea\n",
    "\n",
    "The M/M/s queue is very similar to the M/M/1, with one crucial difference: the **total service rate of the system changes** depending on how many customers are present.\n",
    "\n",
    "Let:\n",
    "- **\\(\\lambda\\):** The total arrival rate to the system.\n",
    "- **\\(\\mu\\):** The service rate of a *single* server.\n",
    "- **s:** The number of servers.\n",
    "\n",
    "The system's effective service rate, \\(\\mu_{eff}\\), depends on the number of customers, \\(n\\):\n",
    "- If \\(n < s\\) (fewer customers than servers), then \\(n\\) servers are busy. The total service rate is \\(\\mu_{eff} = n\\mu\\).\n",
    "- If \\(n \\ge s\\) (all servers are busy), then the system is serving at its maximum capacity. The total service rate is \\(\\mu_{eff} = s\\mu\\).\n",
    "\n",
    "This change in service rate makes the formulas more complex than for the M/M/1 queue, but the underlying principles are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Learn the Definitions and Formulas (for M/M/s)\n",
    "\n",
    "**Traffic Intensity (\\(\\rho\\))**\n",
    "For an M/M/s queue, traffic intensity (or utilization) is defined as the total arrival rate divided by the *maximum* possible service rate.\n",
    "$$ \\rho = \\frac{\\lambda}{s\\mu} $$\n",
    "For the queue to be stable, we must have \\(\\rho < 1\\), which means \\(\\lambda < s\\mu\\). The total arrival rate must be less than the total service capacity.\n",
    "\n",
    "--- \n",
    "\n",
    "**Key Performance Metrics for a Stable M/M/s Queue:**\n",
    "\n",
    "1.  **\\(P_0\\):** Probability that the system is empty. This is the cornerstone calculation.\n",
    "    $$ P_0 = \\left[ \\sum_{n=0}^{s-1} \\frac{(\\lambda/\\mu)^n}{n!} + \\frac{(\\lambda/\\mu)^s}{s!} \\frac{1}{1-\\rho} \\right]^{-1} $$\n",
    "2.  **\\(L_q\\):** Average number of customers in the **queue**. This is also known as the Erlang C formula.\n",
    "    $$ L_q = P_0 \\frac{(\\lambda/\\mu)^s \\rho}{s!(1-\\rho)^2} $$\n",
    "3.  **\\(W_q\\):** Average time a customer spends in the **queue**. (From Little's Law: \\(L_q = \\lambda W_q\\))\n",
    "    $$ W_q = \\frac{L_q}{\\lambda} $$\n",
    "4.  **\\(W\\):** Average time a customer spends in the **system** (waiting + service). The service time is still \\(1/\\mu\\).\n",
    "    $$ W = W_q + \\frac{1}{\\mu} $$\n",
    "5.  **\\(L\\):** Average number of customers in the **system**. (From Little's Law: \\(L = \\lambda W\\))\n",
    "    $$ L = \\lambda W = L_q + \\frac{\\lambda}{\\mu} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Apply and Practice\n",
    "\n",
    "**Scenario:** Let's return to our coffee shop. \n",
    "- Customer arrivals: \\(\\lambda = 20\\) per hour.\n",
    "- Barista service rate: \\(\\mu = 30\\) per hour.\n",
    "\n",
    "In Week 12, we analyzed this as an M/M/1 queue. Now, the owner adds a second barista, making it an **M/M/2 queue** (\\(s=2\\)). Let's compare the performance.\n",
    "\n",
    "### Part A: Theoretical Calculation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def analyze_mms_queue(lambda_rate, mu_rate, s):\n",
    "    \"\"\"Calculates the performance metrics for an M/M/s queue.\"\"\"\n",
    "    # Check for stability\n",
    "    if lambda_rate >= s * mu_rate:\n",
    "        print(\"Warning: Queue is unstable (lambda >= s*mu)\")\n",
    "        return [np.inf] * 5 # Return infinity for all metrics\n",
    "    \n",
    "    rho = lambda_rate / (s * mu_rate)\n",
    "    lambda_mu_ratio = lambda_rate / mu_rate\n",
    "    \n",
    "    # Calculate P_0\n",
    "    sum_term = 0\n",
    "    for n in range(s):\n",
    "        sum_term += (lambda_mu_ratio**n) / math.factorial(n)\n",
    "    \n",
    "    last_term = (lambda_mu_ratio**s / math.factorial(s)) * (1 / (1 - rho))\n",
    "    P0 = 1 / (sum_term + last_term)\n",
    "    \n",
    "    # Calculate Lq, Wq, W, L\n",
    "    Lq = P0 * (lambda_mu_ratio**s * rho) / (math.factorial(s) * (1 - rho)**2)\n",
    "    Wq = Lq / lambda_rate\n",
    "    W = Wq + (1 / mu_rate)\n",
    "    L = lambda_rate * W\n",
    "    \n",
    "    return rho, L, Lq, W, Wq\n",
    "\n",
    "# --- Parameters ---\n",
    "lambda_rate = 20.0  # Arrival rate (customers/hour)\n",
    "mu_rate = 30.0      # Service rate per server (customers/hour)\n",
    "\n",
    "# --- M/M/1 Analysis (from last week) ---\n",
    "rho1, L1, Lq1, W1, Wq1 = analyze_mms_queue(lambda_rate, mu_rate, s=1)\n",
    "\n",
    "# --- M/M/2 Analysis ---\n",
    "rho2, L2, Lq2, W2, Wq2 = analyze_mms_queue(lambda_rate, mu_rate, s=2)\n",
    "\n",
    "# --- Comparison ---\n",
    "print(\"--- Queue Performance Comparison ---\")\n",
    "print(f\"Metric                | M/M/1 (1 Barista) | M/M/2 (2 Baristas) | % Improvement\")\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "\n",
    "def print_comp(name, val1, val2, unit=''):\n",
    "    improvement = (val1 - val2) / val1 * 100 if val1 > 0 else 0\n",
    "    print(f\"{name:<21} | {val1:^17.4f} | {val2:^18.4f} | {improvement:^14.2f}%\")\n",
    "\n",
    "print_comp(\"Server Utilization (ρ)\", rho1, rho2)\n",
    "print_comp(\"Avg # in System (L)\", L1, L2)\n",
    "print_comp(\"Avg # in Queue (Lq)\", Lq1, Lq2)\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print_comp(\"Avg Time in System (W)\", W1 * 60, W2 * 60, 'min')\n",
    "print_comp(\"Avg Time in Queue (Wq)\", Wq1 * 60, Wq2 * 60, 'min')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Interpretation of the Results\n",
    "\n",
    "The comparison is striking! By adding a second barista:\n",
    "\n",
    "- **Server Utilization (ρ):** The utilization *per server* drops from ~67% to ~33%. Each barista is less stressed and has more idle time.\n",
    "- **Average Queue Length (Lq):** The number of people waiting in line drops from 1.33 to just 0.17, an **87.5% reduction**!\n",
    "- **Average Wait Time (Wq):** The time a customer spends waiting for service plummets from 4 minutes to just half a minute, also an **87.5% reduction**.\n",
    "\n",
    "This is a classic result in queuing theory: **pooling resources is incredibly effective**. Instead of creating two separate M/M/1 queues (e.g., one line for each barista), having a single shared queue for multiple servers provides a dramatically better customer experience.\n",
    "\n",
    "The total work done is the same, but the system's ability to absorb random fluctuations in arrivals and service times is much greater. This is why banks, airports, and large stores have a single serpentine queue feeding multiple tellers or agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Simulating an M/M/s Queue (Advanced)\n",
    "\n",
    "Simulating an M/M/s queue is more complex than an M/M/1 because we need to track when each of the `s` servers becomes free. A **priority queue** (or min-heap) is the perfect data structure for this, as it lets us efficiently find the server that will be free next.\n",
    "\n",
    "The logic is as follows:\n",
    "1.  Maintain a priority queue of server-free times. Initially, all `s` servers are free at time 0.\n",
    "2.  When a customer arrives, get the earliest free time from the priority queue.\n",
    "3.  The customer can start service at `max(arrival_time, earliest_free_time)`.\n",
    "4.  Once the customer's service is complete, add the new server-free time back into the priority queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def simulate_mms_queue(lambda_rate, mu_rate, s, max_customers):\n",
    "    \"\"\"Simulates an M/M/s queue using a priority queue for servers.\"\"\"\n",
    "    # State variables\n",
    "    current_time = 0.0\n",
    "    # Priority queue to store the time each server becomes free\n",
    "    server_free_times = [0.0] * s\n",
    "    heapq.heapify(server_free_times)\n",
    "    \n",
    "    # Data collection\n",
    "    total_wait_time = 0.0\n",
    "    total_system_time = 0.0\n",
    "    \n",
    "    for _ in range(max_customers):\n",
    "        # 1. Generate next arrival\n",
    "        inter_arrival_time = np.random.exponential(1.0 / lambda_rate)\n",
    "        current_time += inter_arrival_time\n",
    "        arrival_time = current_time\n",
    "        \n",
    "        # 2. Find the earliest available server\n",
    "        earliest_free_time = heapq.heappop(server_free_times)\n",
    "        \n",
    "        # 3. Calculate wait time\n",
    "        start_service_time = max(arrival_time, earliest_free_time)\n",
    "        wait_time = start_service_time - arrival_time\n",
    "        total_wait_time += wait_time\n",
    "        \n",
    "        # 4. Generate service time and update the server's next free time\n",
    "        service_time = np.random.exponential(1.0 / mu_rate)\n",
    "        departure_time = start_service_time + service_time\n",
    "        heapq.heappush(server_free_times, departure_time)\n",
    "        \n",
    "        # 5. Calculate system time\n",
    "        system_time = departure_time - arrival_time\n",
    "        total_system_time += system_time\n",
    "        \n",
    "    # Calculate averages\n",
    "    avg_Wq = total_wait_time / max_customers\n",
    "    avg_W = total_system_time / max_customers\n",
    "    \n",
    "    return avg_W, avg_Wq\n",
    "\n",
    "# --- Simulation of M/M/2 ---\n",
    "N_CUSTOMERS = 100000\n",
    "sim_W2, sim_Wq2 = simulate_mms_queue(lambda_rate, mu_rate, s=2, max_customers=N_CUSTOMERS)\n",
    "\n",
    "print(\"\\n--- M/M/2 Simulation Results ---\")\n",
    "print(f\"Simulated Avg time in system (W): {sim_W2 * 60:.4f} minutes (Theoretical: {W2 * 60:.4f})\")\n",
    "print(f\"Simulated Avg time in queue (Wq): {sim_Wq2 * 60:.4f} minutes (Theoretical: {Wq2 * 60:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation results again align perfectly with the theoretical formulas, confirming our understanding of the M/M/s model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "In this notebook, we've extended our analysis to multi-server queues:\n",
    "1.  The **M/M/s queue** models a system with Poisson arrivals, Exponential service times, and `s` parallel servers.\n",
    "2.  The formulas are more complex but allow for precise analysis.\n",
    "3.  We demonstrated the immense benefit of **resource pooling**: an M/M/2 system offers dramatically better performance than an M/M/1 system with the same total capacity, especially regarding customer wait times.\n",
    "4.  We built a more advanced discrete-event simulation using a priority queue to model the multi-server system.\n",
    "\n",
    "In our final week, **Week 14**, we will study **Birth-and-Death Processes**. This is a general framework that unifies many of the models we've seen, including the M/M/1 and M/M/s queues, by looking at them as processes where the state only ever changes by +1 or -1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}