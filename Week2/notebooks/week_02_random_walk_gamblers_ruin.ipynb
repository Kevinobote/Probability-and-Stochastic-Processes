{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Random Walk & Gambler's Ruin Problem\n",
    "\n",
    "**Objective:** Understand the Random Walk as a fundamental stochastic process and analyze one of its most famous applications, the Gambler's Ruin problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The Random Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Build Intuition\n",
    "\n",
    "Imagine a person walking along a straight line. They start at position zero. Every second, they flip a coin. If it's heads, they take one step to the right (+1). If it's tails, they take one step to the left (-1). Their path is unpredictable, yet it's built from simple, random steps. This is the essence of a **random walk**.\n",
    "\n",
    "This simple model can describe many real-world phenomena:\n",
    "- The movement of a stock price (up or down).\n",
    "- The path of a molecule in a gas.\n",
    "- A foraging animal's search for food."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Understand the Core Idea\n",
    "\n",
    "A random walk is a path built by summing up a sequence of random steps.\n",
    "\n",
    "- **Position at time `n`:** This is the sum of all the random steps taken up to that point, plus the starting position.\n",
    "- **Random Step:** Each step is a random variable. In the simplest case, the steps are independent and identically distributed (i.i.d.).\n",
    "\n",
    "The key idea is that the *next position only depends on the current position and the next random step*. This is a precursor to the Markov property we will see in Week 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Learn the Definitions and Formulas\n",
    "\n",
    "**Definition: Simple Symmetric Random Walk**\n",
    "\n",
    "A simple 1D random walk is a discrete-time stochastic process \\(S_n\\) defined by:\n",
    "\n",
    "$$ S_n = S_0 + \\sum_{i=1}^{n} X_i $$\n",
    "\n",
    "Where:\n",
    "- \\(S_n\\) is the position at time step \\(n\\).\n",
    "- \\(S_0\\) is the starting position (often 0).\n",
    "- \\(X_i\\) are independent and identically distributed (i.i.d.) random variables representing the steps.\n",
    "\n",
    "For a **simple symmetric** random walk, the steps \\(X_i\\) are:\n",
    "\n",
    "$$ X_i = \\begin{cases} +1 & \\text{with probability } p = 0.5 \\\\ -1 & \\text{with probability } q = 1-p = 0.5 \\end{cases} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Apply and Practice\n",
    "\n",
    "Let's simulate a few random walks to see how different they can look, even when they come from the exact same process. This highlights the \"randomness\" inherent in a stochastic process. A single realization (one simulated path) is just one of infinitely many possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a style for plots for better visualization\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_random_walk(num_steps, start_pos=0):\n",
    "    \"\"\"Simulates a 1D simple symmetric random walk.\"\"\"\n",
    "    # Steps are +1 or -1 with equal probability\n",
    "    steps = np.random.choice([-1, 1], size=num_steps)\n",
    "    # The first position is the starting position, so we prepend it\n",
    "    # and then take the cumulative sum of steps.\n",
    "    positions = np.concatenate(([start_pos], steps)).cumsum()\n",
    "    return positions\n",
    "\n",
    "# Simulation parameters\n",
    "N_STEPS = 200\n",
    "N_WALKS = 5 # Number of different walks to simulate\n",
    "time_steps = np.arange(N_STEPS + 1)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for i in range(N_WALKS):\n",
    "    # Run a new simulation for each walk\n",
    "    walk_path = simulate_random_walk(N_STEPS)\n",
    "    plt.step(time_steps, walk_path, where='mid', label=f'Walk {i+1}')\n",
    "\n",
    "plt.title(f'{N_WALKS} Simulations of a Simple Random Walk')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Position')\n",
    "plt.axhline(0, color='black', linestyle='--', label='Start Position')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The Gambler's Ruin Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Build Intuition\n",
    "\n",
    "The Gambler's Ruin is a classic application of the random walk. Imagine a gambler starting with some money. They play a series of games, winning or losing $1 in each round. They have two goals:\n",
    "1.  A **winning goal**: a target amount of money they want to reach.\n",
    "2.  A **losing limit**: $0, at which point they are \"ruined\" and must stop playing.\n",
    "\n",
    "The gambler's fortune is a random walk, but with a twist: there are two **absorbing barriers**. Once the gambler's fortune hits either 0 or their target, the game ends. The key question is: what is the probability that the gambler goes broke before reaching their goal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Understand the Core Idea\n",
    "\n",
    "This problem introduces the concept of **absorbing states** to a random walk.\n",
    "\n",
    "- **State:** The gambler's current capital (e.g., \\$k).\n",
    "- **State Space:** The possible amounts of money the gambler can have, from \\$0 to \\$N (the target). So, the states are \\({0, 1, 2, ..., N}\\).\n",
    "- **Transitions:** In each step, the state can change from \\(k\\) to \\(k+1\\) (win) or \\(k-1\\) (loss).\n",
    "- **Absorbing Barriers:** If the state becomes 0 or N, it stays there forever. The random walk stops.\n",
    "\n",
    "We want to find the probability of being absorbed at the 0 barrier, given a starting capital \\(k\\)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Learn the Definitions and Formulas\n",
    "\n",
    "Let:\n",
    "- \\(k\\) = The gambler's initial capital.\n",
    "- \\(N\\) = The target capital (the house's capital or winning goal).\n",
    "- \\(p\\) = The probability of winning \\$1 in a single game.\n",
    "- \\(q = 1-p\\) = The probability of losing \\$1 in a single game.\n",
    "- \\(P_k\\) = The probability of eventual ruin (reaching 0) given a starting capital of \\(k\\).\n",
    "\n",
    "The probability of ruin, \\(P_k\\), can be calculated with the following formulas:\n",
    "\n",
    "1.  **For a biased game (\\(p \\neq 0.5\\)):**\n",
    "$$ P_k = \\frac{(q/p)^k - (q/p)^N}{1 - (q/p)^N} $$\n",
    "\n",
    "2.  **For a fair game (\\(p = 0.5\\)):**\n",
    "$$ P_k = 1 - \\frac{k}{N} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Apply and Practice\n",
    "\n",
    "Let's write a function to calculate the probability of ruin and then visualize how this probability changes based on the starting capital and the fairness of the game. This is where the formula becomes intuitive.\n",
    "\n",
    "**Scenario:** A gambler starts with some money and wants to reach a total of \\$100. What is their probability of going broke?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_of_ruin(start_capital, target_capital, win_prob):\n",
    "    \"\"\"\n",
    "    Calculates the probability of a gambler going broke.\n",
    "    \n",
    "    Args:\n",
    "        start_capital (int): The initial amount of money (k).\n",
    "        target_capital (int): The winning goal (N).\n",
    "        win_prob (float): The probability of winning a single round (p).\n",
    "        \n",
    "    Returns:\n",
    "        float: The probability of ruin.\n",
    "    \"\"\"\n",
    "    # Handle the edge case of a fair game (p=0.5)\n",
    "    if win_prob == 0.5:\n",
    "        return 1 - (start_capital / target_capital)\n",
    "    \n",
    "    # Handle the biased game case (p != 0.5)\n",
    "    q = 1 - win_prob\n",
    "    ratio = q / win_prob\n",
    "    \n",
    "    numerator = (ratio ** start_capital) - (ratio ** target_capital)\n",
    "    denominator = 1 - (ratio ** target_capital)\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "# --- Parameters ---\n",
    "TARGET = 100 # The gambler's goal is $100\n",
    "\n",
    "# Let's test with a specific starting point\n",
    "start = 50\n",
    "p_fair = 0.5\n",
    "p_unfair = 0.49 # A game slightly biased against the gambler\n",
    "\n",
    "ruin_prob_fair = probability_of_ruin(start, TARGET, p_fair)\n",
    "ruin_prob_unfair = probability_of_ruin(start, TARGET, p_unfair)\n",
    "\n",
    "print(f\"Starting with ${start} and aiming for ${TARGET}:\")\n",
    "print(f\"- In a fair game (p=0.5), probability of ruin is: {ruin_prob_fair:.2%}\")\n",
    "print(f\"- In an unfair game (p=0.49), probability of ruin is: {ruin_prob_unfair:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how even a tiny 1% disadvantage (`p=0.49` instead of `p=0.5`) dramatically increases the probability of ruin! Let's visualize this effect across all possible starting amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a range of starting capitals from $1 to $99\n",
    "k_values = np.arange(1, TARGET)\n",
    "\n",
    "# Calculate ruin probabilities for each starting capital\n",
    "ruin_fair_game = [probability_of_ruin(k, TARGET, p_fair) for k in k_values]\n",
    "ruin_unfair_game = [probability_of_ruin(k, TARGET, p_unfair) for k in k_values]\n",
    "ruin_favorable_game = [probability_of_ruin(k, TARGET, 0.51) for k in k_values]\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.plot(k_values, ruin_fair_game, label='Fair Game (p=0.5)', linestyle='--')\n",
    "plt.plot(k_values, ruin_unfair_game, label='Unfavorable Game (p=0.49)', color='red')\n",
    "plt.plot(k_values, ruin_favorable_game, label='Favorable Game (p=0.51)', color='green')\n",
    "\n",
    "plt.title('Gambler\\'s Ruin: Probability of Ruin vs. Starting Capital')\n",
    "plt.xlabel('Starting Capital ($k$)')\n",
    "plt.ylabel('Probability of Ruin')\n",
    "plt.xlim(0, TARGET)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True, which='both', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of the Plot:**\n",
    "- **Fair Game (Blue Dashed Line):** The probability of ruin decreases linearly. If you start with \\$50 out of \\$100, you have a 50% chance of ruin. If you start with \\$90, you have only a 10% chance.\n",
    "- **Unfavorable Game (Red Line):** The curve is bowed upwards. Even with a tiny disadvantage, the probability of ruin is significantly higher than in a fair game, especially if you start with a smaller amount of capital. Notice that even starting with \\$80 gives you a ~40% chance of ruin!\n",
    "- **Favorable Game (Green Line):** The curve is bowed downwards. A small advantage drastically reduces your chance of ruin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "In this notebook, we've explored:\n",
    "1.  The **Random Walk** as a sum of i.i.d. random steps.\n",
    "2.  How to simulate and visualize random walks to understand their inherent variability.\n",
    "3.  The **Gambler's Ruin Problem** as a random walk with absorbing barriers.\n",
    "4.  How to use the formal equations to calculate the probability of ruin and see how sensitive it is to even a small bias in the game's fairness.\n",
    "\n",
    "The Random Walk is a fundamental example of a **Markov Chain**, which is our topic for **Weeks 3-4**. A process has the Markov property if the future is independent of the past, given the present. In our random walk, to know the next position, all we need is the current position—we don't need to know how we got there. We will formalize this powerful idea next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}